% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GB_NPMLE.R
\name{GB_NPMLE}
\alias{GB_NPMLE}
\title{Generative Bootstrap NPMLE}
\usage{
GB_NPMLE(X=NULL, Y, param=0, distribution=NULL, S=100, p=1,
hidden_size=500, save=0, num_it=NULL, q=100, M=100, zm=150,
gpu_ind=0, N=100, lr0=0.005, verb=1, tol=0.005, n=NULL, lrDecay = 0,
save_path=NULL)
}
\arguments{
\item{X}{predictor Variable.}

\item{Y}{response Variable.}

\item{param}{nuisance parameter value. Param = 0 indicates there is no nuisance parameter.}

\item{distribution}{probabilistic distribution of Y, including:
"Gaussian location", "Poisson", "Gamma rate" and "Binomial".}

\item{S}{size of subgroup. Sample size/S returns total number of subgroups.}

\item{hidden_size}{number of hidden neurons at each layer.}

\item{save}{save the trained generator function. 1: save; 0: no save. Default is 0.}

\item{num_it}{number of iterations for training.}

\item{l}{number of replications of generator's output.}

\item{M}{number of Monte Carlo iterations for approximating E_z.}

\item{q}{length of auxiliary random variable z.}

\item{p}{the dimension of Predictor Variable;Default is 1.}

\item{gpu_ind}{gpu index.}

\item{N}{number of Monte Carlo iterations for approximating E_w.}

\item{lr0}{learning rate, default is 0.0005.}

\item{verb}{print information while training generator.}

\item{tol}{tolerance to determine whether EM algorithm converges;default is 0.005.}

\item{lrDecay}{lrDecay = 1: using decaying learning rate.}

\item{lrpower}{decay rate of learning rate, default is 0.2.}

\item{save_path}{the directory path where the trained generator function will be saved.}
}
\value{
GB_NPMLE function returns a list which involves NPMLE bootstrap samples, Generator training time, EM algorithm convergence time and Bootstrap sample generation time.
}
\description{
Train the generator of GB-NPMLE (Generative Bootstrap NPMLE).GB-NPMLE
mainly focuses on NPMLE estimation of univariate mixture model estimation.
python(>=3.7) and pytorch
are needed to be installed in advance. R pakcage 'reticulate' is also required.
}
\examples{
### Gaussian Location Mixture model example
library(reticulate)
set.seed(2^2+2021)
sigma = 0.5;n = 100
theta = c(rep(0,0.2*n),
          rep(5,0.8*n))
Y = theta+rnorm(n,0,sigma)
fit_GBnpmle = GB_NPMLE(Y=Y, param=sigma, distribution="Gaussian location", num_it=1000, n=n, p=1, S=100, q=100, verb=1, hidden_size=500)
Sample_GBnpmle = GB_NPMLE_Sample(fit_GBnpmle[[1]], boot_size=10000)
hist(Sample_GBnpmle$Theta, breaks=25, main="", xlab=expression(theta), freq=F, col="white", border=T)
points(x=0, y=0, pch=4, col='red', lwd=2)
points(x=5, y=0, pch=4, col='red', lwd=2)
### Poisson Mixture model example
set.seed(1)
n = 1000
theta = rgamma(n,3,1)
Y = rpois(n,lambda=theta)
fit_GBnpmle = GB_NPMLE(Y=Y, param=0, distribution="Poisson", num_it=1000, lrDecay=0, n=n, p=1, S=100, q=1, verb=1, hidden_size=500, tol=0.0001)
Sample_GBnpmle = GB_NPMLE_Sample(fit_GBnpmle[[1]], boot_size=10000)
hist(Sample_GBnpmle$Theta, breaks=25, main="", xlab=expression(theta), freq=F, col="white", border=T)
lines(density(rgamma(1E5,3,1)))
### Gamma shape Mixture model example
set.seed(1^2+2021)
gamma_shape = 10;n = 100
theta = c(rep(1,0.2*n),
          rep(10,0.8*n))
Y = rgamma(n,rate=theta,shape=gamma_shape)
fit_GBnpmle = GB_NPMLE(Y=Y, param=gamma_shape, distribution="Gamma rate", num_it=2000, n=n, p=1, S=100, q=100, verb=1, hidden_size=500)
Sample_GBnpmle = GB_NPMLE_Sample(fit_GBnpmle[[1]], boot_size=10000)
hist(Sample_GBnpmle$Theta, breaks=25, main="", xlab=expression(theta), freq=F, col="white", border=T, xlim=c(0,14))
points(x=1, y=0, pch=4, col='red', lwd=2)
points(x=10, y=0, pch=4, col='red', lwd=2)
### Binomial probability Mixture model example
set.seed(1^2+2021)
bino_n = 10;n = 100
theta = c(rep(0.2,0.5*n),
          rep(0.8,0.5*n))
Y = rbinom(n, size=bino_n, prob=theta)
fit_GBnpmle = GB_NPMLE(Y=Y, param=bino_n, distribution="Binomial", num_it=2000, n=n, p=1, S=100, q=100, verb=1, hidden_size=500)
Sample_GBnpmle = GB_NPMLE_Sample(fit_GBnpmle[[1]], boot_size=10000)
hist(Sample_GBnpmle$Theta, breaks=25, main="", xlab=expression(theta), freq=F, col="white", border=T)
points(x=0.2, y=0, pch=4, col='red', lwd=2)
points(x=0.8, y=0, pch=4, col='red', lwd=2)
### Posisson Real data analysis
#Thailand datasaet
#Y = c(rep(0,120),rep(1,64),rep(2,69),rep(3,72),rep(4,54),rep(5,35),rep(6,36),rep(7,25),
#rep(8,25),rep(9,19),rep(10,18),rep(11,18),rep(12,13),rep(13,4),rep(14,3),rep(15,6),
#rep(16,6),rep(17,5),rep(18,1),rep(19,3),rep(20,1),rep(21,2),rep(23,1),rep(24,2))
#Mortality dataset
Y = c(rep(0,162),rep(1,267),rep(2,271),rep(3,185),rep(4,111),rep(5,61),rep(6,27),rep(7,8),
rep(8,3),rep(9,1))
n = length(Y)
fit_GBnpmle = GB_NPMLE(Y=Y, param=0, distribution="Poisson", boot_size=1000, num_it=2000, lrDecay=0, n=n, p=1, S=100, q=100, verb=1, hidden_size=500)
Sample_GBnpmle = GB_NPMLE_Sample(fit_GBnpmle[[1]], boot_size=10000)
hist(Sample_GBnpmle$Theta, breaks=25, main="", xlab=expression(theta), freq=F, col="white", border=T)
}
\seealso{
\code{\link{GB_NPMLE_Sample}},\code{\link{GB_NPMLE_Load}}
}
\author{
Shijie Wang and Minsuk Shin
}
